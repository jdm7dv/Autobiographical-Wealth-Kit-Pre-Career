max v2;#N vpatcher 12 40 642 480;#P user multiSlider 258 54 71 75 0. 1. 2 2681 47;#P comment 144 332 100 196617 save weights to file;#P comment 144 310 100 196617 retreive weights file;#P comment 144 28 100 196617 train net on current training set (number of epochs;#P comment 144 286 100 196617 retreive training set;#P comment 144 246 100 196617 sets error tolerance level for termination of training;#P comment 144 203 100 196617 dumps current training set to MAX window;#P comment 144 147 100 196617 dumps current weight values and output slope factors to MAX window;#P comment 144 117 100 196617 toggles internal debugging switch;#P comment 144 73 100 196617 outputs the current output unit activation levels;#P comment 144 357 100 196617 dump net stats to MAX window;#P message 344 352 61 196617 reinitialise;#P message 344 321 93 196617 recognize 0.1 0.1;#P message 344 101 55 196617 learn 0.9;#P message 344 58 74 196617 hid_slope 1.;#P message 344 24 65 196617 graphicsOff;#P message 344 6 61 196617 graphicsOn;#P comment 462 349 100 196617 reinitialise weights to small random values;#P comment 462 318 100 196617 feed forward pass through the network;#P comment 462 271 100 196617 learning parameters for output slope factor;#P comment 462 234 100 196617 set output units slope factors;#P comment 462 101 100 196617 do a back propagation pass by giving the target value For example: stimulate the net with a list and then tell it what the target value should be (long-cut for bp_learn);#P comment 462 56 100 196617 set hidden units slope factors;#P comment 462 5 100 196617 turn graphics display on and off;#P comment 462 388 100 196617 double-click here to see more about weights file format;#P newex 342 388 96 196617 WeightsFileFormat;#P comment 143 388 100 196617 double-click here to see more about training file format;#P message 344 127 75 196617 xValidateTest;#P message 344 148 78 196617 xValidateTrain;#P message 43 219 63 196617 dump_train;#P message 43 202 60 196617 dump_test;#P message 43 267 75 196617 get_test_data;#P newex 43 388 98 196617 TrainingFileFormat;#P message 43 357 40 196617 status;#P message 43 332 74 196617 save_weights;#P message 43 310 69 196617 get_weights;#P message 43 73 34 196617 bang;#P message 43 117 37 196617 debug;#P message 43 147 35 196617 dump;#P message 43 246 69 196617 error 0.1;#P message 43 286 92 196617 get_training_data;#P message 43 28 83 196617 auto_learn 300;#P flonum 344 250 35 9 0 0 0 3;#P message 344 231 75 196617 out_slope 3.;#P message 344 268 101 196617 out_slope_learn \$1;#P flonum 344 285 35 9 0 0 0 3;#P message 344 303 99 196617 out_slope_mom \$1;#P message 343 213 75 196617 lambda 0.78;#P user MaxNet 258 136 59 84 2 131073 1 0.7 0.9 0.5;#P comment 330 173 100 196617 MAXNet - neural net simulator;#P user multiSlider 258 294 29 55 0. 1. 1 2681 15;#P newex 258 273 56 196617 route list;#P newex 293 308 35 196617 print;#P message 348 79 111 196617 bpInError 0.9 0.9 0.9;#P connect 53 0 5 0;#P hidden connect 41 0 5 0;#P hidden connect 40 0 5 0;#P hidden connect 39 0 5 0;#P hidden connect 38 0 5 0;#P hidden connect 37 0 5 0;#P hidden connect 26 0 5 0;#P hidden connect 25 0 5 0;#P hidden connect 24 0 5 0;#P hidden connect 23 0 5 0;#P hidden connect 22 0 5 0;#P hidden connect 20 0 5 0;#P hidden connect 19 0 5 0;#P hidden connect 18 0 5 0;#P hidden connect 17 0 5 0;#P hidden connect 16 0 5 0;#P hidden connect 15 0 5 0;#P hidden connect 14 0 5 0;#P hidden connect 13 0 5 0;#P hidden connect 12 0 5 0;#P hidden connect 10 0 5 0;#P connect 8 0 7 0;#P hidden connect 9 0 5 0;#P hidden connect 7 0 5 0;#P hidden connect 6 0 5 0;#P connect 0 0 5 0;#P connect 11 0 9 0;#P hidden connect 42 0 5 0;#P connect 2 0 3 0;#P connect 2 1 1 0;#P connect 5 0 2 0;#P pop;